{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a507adcc",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641d0d3d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53544be",
   "metadata": {},
   "source": [
    "##### What is Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb4e95",
   "metadata": {},
   "source": [
    "Web scraping refers to the process of extracting data from websites by parsing the HTML or interacting with web applications.\n",
    "* Data Analysis: Collecting data for statistical analysis, research, and market analysis.\n",
    "* Content Aggregation: Gathering similar content from multiple websites (e.g., news, blogs).\n",
    "* Automation: Performing repetitive tasks such as filling out forms and submitting data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198f0d37",
   "metadata": {},
   "source": [
    "##### Understanding HTTP Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589996d1",
   "metadata": {},
   "source": [
    "* Request: When you enter a URL in a web browser and hit enter, the browser sends an HTTP request to the server specified by the URL.\n",
    "* Response: The server processes the request and responds with an HTTP response. If the request is for a web page, the response usually includes an HTML document. <br>\n",
    "The browser then interprets and renders this HTML document to display the web page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193d441",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/songtuf/webscraping/main/html_request.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7abf4",
   "metadata": {},
   "source": [
    "## HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa4682",
   "metadata": {},
   "source": [
    "### Why HTML Important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69646aaf",
   "metadata": {},
   "source": [
    "* HTML stands for HyperText Markup Language.\n",
    "* HTML provides the structure of web pages by defining elements such as headings, paragraphs, lists, links, images, and more.\n",
    "* HTML uses a standarized set of tags to define the structure and layout of a web document. [Link to the list of html tags](https://www.w3schools.com/TAGS/default.asp)\n",
    "* HTML enables the creation of hypertext links -- connect different web pages and resources across the internet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c20de",
   "metadata": {},
   "source": [
    "### HTML Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d4836",
   "metadata": {},
   "source": [
    "![Directory Structure](https://raw.githubusercontent.com/songtuf/webscraping/main/html_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fe5a8",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>  <!-- Declaration -->\n",
    "<HTML>           <!-- Root of HTML doc -->\n",
    "    <HEAD>       <!-- Metadata -->\n",
    "        <TITLE>My Title</TITLE> \n",
    "    </HEAD>\n",
    "    <BODY>      <!-- contents -->\n",
    "        <H1>A Heading</H1>\n",
    "        <a href=\"https://www.google.com/\">Link text</a>\n",
    "    </BODY>\n",
    "</HTML> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200e16b",
   "metadata": {},
   "source": [
    "### HTML Element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4d4407",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/songtuf/webscraping/main/HTML_tags2.png\" width=\"700\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a78b8",
   "metadata": {},
   "source": [
    "### Your Turn! -- HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c4b55",
   "metadata": {},
   "source": [
    "1. Start a new Markdown chunk below\n",
    "2. Decalre HTML document <br>\n",
    "```<!DOCTYPE html>```\n",
    "3. Insert the following tags: html, head, body, div, and H1 \n",
    "    ```\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "        <head>\n",
    "        </head>\n",
    "        <body>\n",
    "        </body>\n",
    "    </html>\n",
    "    ```\n",
    "4. Insert `title` tag under the `head` tag\n",
    "    ```\n",
    "    <head>\n",
    "        <title>HTML Tutorial</title>\n",
    "    </head>\n",
    "    ```\n",
    "5. Create a division using the `div` tag under the `body` tag\n",
    "    ```\n",
    "    <body>\n",
    "        <H1> This is H1 heading</H1>\n",
    "        <p> This is a paragraph</p>\n",
    "        <div>\n",
    "            <H3>This is H3 heading</H3>\n",
    "        </div>\n",
    "    </body>\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adee85e",
   "metadata": {},
   "source": [
    "Double click on this markdown chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f511fa6",
   "metadata": {},
   "source": [
    "## Essential Packages for Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c24e1",
   "metadata": {},
   "source": [
    "* `requests` - HTTP library that makes HTTP requests\n",
    "    - We will use the `GET` request to retrieve data from the server\n",
    "* `BeautifulSoup` - Popular library that extract data from HTML and XML documents\n",
    "* `Pandas` - Powerful library for data manipulation and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc7964",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43911f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk contains Python code\n",
    "# Text following the `#` symbol represents comments\n",
    "# Python ignores comments during execution\n",
    "# Comments are provided to help readers understand the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bb164b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to import the requests and beautiful soup package\n",
    "# The two lines should run smoothly\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45d311e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As an example, we will scrape example.com\n",
    "# Define object `url` to be http://example.com\n",
    "url = \"http://example.com\"\n",
    "\n",
    "# Use the `get` request to retrieve the data\n",
    "response = requests.get(url)\n",
    "# Check respons\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cea86",
   "metadata": {},
   "source": [
    "### Selected HTTP status codes\n",
    "* 200: OK -- Request was successful\n",
    "* 401: Unauthorized -- Lacks valid authentication credentials for the requested source\n",
    "* 403: Forbidden -- Server refused to process it\n",
    "* 404: Not Found -- Server cannot find the requested resource\n",
    "* 502: Bad Gateway -- Server received an invalid response from the upstream server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text part of the response\n",
    "html_content = response.text\n",
    "html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7672e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object and specify the parser\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "# Note the difference between html_content output and the soup output\"\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30e83f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Domain\n"
     ]
    }
   ],
   "source": [
    "# Extract Information using tags\n",
    "# Find the first 'h1' tag\n",
    "h1_tag = soup.find('h1')\n",
    "print(h1_tag.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b25013d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `find_all` function to extract multiple tags\n",
    "# Example, find all 'p' tags\n",
    "p_tags = soup.find_all('p')\n",
    "p_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9644ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that multiple p tags are saved in a list.\n",
    "p_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37dbec26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7b758c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'More information...'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text infromation of the `a` tag\n",
    "soup.find('a').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ddc48d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.iana.org/domains/example'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract hypertext reference (href) link in the `a` tag\n",
    "soup.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e1303a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.iana.org/domains/example'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the extracted url\n",
    "next_url = soup.find('a')['href']\n",
    "next_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9230f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/go/rfc2606\">RFC 2606</a>, <a href=\"/go/rfc6761\">RFC 6761</a>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make another get request, but now using the extracted domain\n",
    "response = requests.get(next_url)\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "# Try to extract the two urls for \"RFC 2606\" and \"RFC 6761\".\n",
    "# Use F12 key (for Windows) or CMD+ALT+I (Mac) to open Inspect on your web browser\n",
    "# Use the `inspector` to identify path to the \"RFC 2606\" and \"RFC 6761\"\n",
    "# Hint1: You may have to dive multiple layers of tags. Use `select` instead of `find_all` and then use the `>` symbol if you want to reach the child tag\n",
    "# Hint2: the `main` tag may not be supported. Use other tags.\n",
    "# Hint3: You may have to specify a certain `div`tag. Use it's class\n",
    "soup.select('div[class=help-article] > p > a')\n",
    "# Note that the `select` function naturally puts multiple tags into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a4181",
   "metadata": {},
   "source": [
    "### Your Turn! -- BeautifulSoup\n",
    "The goal is to extract the link for \"IANA-managed Reserved Domains\"\n",
    "\n",
    "1. Send a `get` request to `'https://www.iana.org/domains/example'`\n",
    "2. Use F12 key (for Windows) or CMD+ALT+I (Mac) to open Inspect on your web browser\n",
    "3. Use the `inspector` to identify path to the \"IANA-managed Reserved Domains\"\n",
    "4. Extract the url link of \"IANA-managed Reserved Domains\" and save it as `html_ex`\n",
    "Hint: The `html_ex` object will be a list if you used the `select` function <br>\n",
    "In order to use `[\"href\"]`, select the element from the list. Example: `html_ex[0]['href']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b7671eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.iana.org/help/example-domains\")\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "html_ex = soup.select(\"div[class=help-article] > ul > li > a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "91dc186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.iana.org/domains/reserved'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the extracted url will be incomplete.\n",
    "# This is because the root node is not provided.\n",
    "# Check the root node -- \"https://www.iana.org\"\n",
    "# Add the root node to the extracted url address\n",
    "\"https://www.iana.org\" + html_ex[0]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736221d",
   "metadata": {},
   "source": [
    "### Saving a Table\n",
    "* We will use the Pandas package to extract table in a nice dataframe format\n",
    "* Let's use the new url address `https://www.iana.org/domains/reserved`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "060aad85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songt\\AppData\\Local\\Temp\\ipykernel_28320\\152429976.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(soup))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Domain (A-label)</th>\n",
       "      <th>Language</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>إختبار</td>\n",
       "      <td>XN--KGBECHTV</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>آزمایشی</td>\n",
       "      <td>XN--HGBK6AJ7F53BBA</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>测试</td>\n",
       "      <td>XN--0ZWM56D</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Han (Simplified variant)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>測試</td>\n",
       "      <td>XN--G6W251D</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Han (Traditional variant)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>испытание</td>\n",
       "      <td>XN--80AKHBYKNJ4F</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Cyrillic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>परीक्षा</td>\n",
       "      <td>XN--11B5BS3A9AJ6G</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Devanagari (Nagari)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>δοκιμή</td>\n",
       "      <td>XN--JXALPDLP</td>\n",
       "      <td>Greek, Modern (1453-)</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>테스트</td>\n",
       "      <td>XN--9T4B11YI5A</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Hangul (Hangŭl, Hangeul)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>טעסט</td>\n",
       "      <td>XN--DEBA0AD</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>Hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>テスト</td>\n",
       "      <td>XN--ZCKZAH</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Katakana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>பரிட்சை</td>\n",
       "      <td>XN--HLCJ6AYA9ESC7A</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Domain    Domain (A-label)               Language  \\\n",
       "0      إختبار        XN--KGBECHTV                 Arabic   \n",
       "1     آزمایشی  XN--HGBK6AJ7F53BBA                Persian   \n",
       "2          测试         XN--0ZWM56D                Chinese   \n",
       "3          測試         XN--G6W251D                Chinese   \n",
       "4   испытание    XN--80AKHBYKNJ4F                Russian   \n",
       "5     परीक्षा   XN--11B5BS3A9AJ6G                  Hindi   \n",
       "6      δοκιμή        XN--JXALPDLP  Greek, Modern (1453-)   \n",
       "7         테스트      XN--9T4B11YI5A                 Korean   \n",
       "8        טעסט         XN--DEBA0AD                Yiddish   \n",
       "9         テスト          XN--ZCKZAH               Japanese   \n",
       "10    பரிட்சை  XN--HLCJ6AYA9ESC7A                  Tamil   \n",
       "\n",
       "                       Script  \n",
       "0                      Arabic  \n",
       "1                      Arabic  \n",
       "2    Han (Simplified variant)  \n",
       "3   Han (Traditional variant)  \n",
       "4                    Cyrillic  \n",
       "5         Devanagari (Nagari)  \n",
       "6                       Greek  \n",
       "7    Hangul (Hangŭl, Hangeul)  \n",
       "8                      Hebrew  \n",
       "9                    Katakana  \n",
       "10                      Tamil  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the pandas library and name it pd to make it abstract\n",
    "import pandas as pd\n",
    "\n",
    "response = requests.get('https://www.iana.org/domains/reserved')\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "table = pd.read_html(str(soup))\n",
    "# Note that table will be saved in a list\n",
    "table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6fc38357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songt\\AppData\\Local\\Temp\\ipykernel_28320\\2645130581.py:4: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  pd.read_html(specific_table_html)[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Domain (A-label)</th>\n",
       "      <th>Language</th>\n",
       "      <th>Script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>إختبار</td>\n",
       "      <td>XN--KGBECHTV</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>آزمایشی</td>\n",
       "      <td>XN--HGBK6AJ7F53BBA</td>\n",
       "      <td>Persian</td>\n",
       "      <td>Arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>测试</td>\n",
       "      <td>XN--0ZWM56D</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Han (Simplified variant)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>測試</td>\n",
       "      <td>XN--G6W251D</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Han (Traditional variant)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>испытание</td>\n",
       "      <td>XN--80AKHBYKNJ4F</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Cyrillic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>परीक्षा</td>\n",
       "      <td>XN--11B5BS3A9AJ6G</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Devanagari (Nagari)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>δοκιμή</td>\n",
       "      <td>XN--JXALPDLP</td>\n",
       "      <td>Greek, Modern (1453-)</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>테스트</td>\n",
       "      <td>XN--9T4B11YI5A</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Hangul (Hangŭl, Hangeul)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>טעסט</td>\n",
       "      <td>XN--DEBA0AD</td>\n",
       "      <td>Yiddish</td>\n",
       "      <td>Hebrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>テスト</td>\n",
       "      <td>XN--ZCKZAH</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Katakana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>பரிட்சை</td>\n",
       "      <td>XN--HLCJ6AYA9ESC7A</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Domain    Domain (A-label)               Language  \\\n",
       "0      إختبار        XN--KGBECHTV                 Arabic   \n",
       "1     آزمایشی  XN--HGBK6AJ7F53BBA                Persian   \n",
       "2          测试         XN--0ZWM56D                Chinese   \n",
       "3          測試         XN--G6W251D                Chinese   \n",
       "4   испытание    XN--80AKHBYKNJ4F                Russian   \n",
       "5     परीक्षा   XN--11B5BS3A9AJ6G                  Hindi   \n",
       "6      δοκιμή        XN--JXALPDLP  Greek, Modern (1453-)   \n",
       "7         테스트      XN--9T4B11YI5A                 Korean   \n",
       "8        טעסט         XN--DEBA0AD                Yiddish   \n",
       "9         テスト          XN--ZCKZAH               Japanese   \n",
       "10    பரிட்சை  XN--HLCJ6AYA9ESC7A                  Tamil   \n",
       "\n",
       "                       Script  \n",
       "0                      Arabic  \n",
       "1                      Arabic  \n",
       "2    Han (Simplified variant)  \n",
       "3   Han (Traditional variant)  \n",
       "4                    Cyrillic  \n",
       "5         Devanagari (Nagari)  \n",
       "6                       Greek  \n",
       "7    Hangul (Hangŭl, Hangeul)  \n",
       "8                      Hebrew  \n",
       "9                    Katakana  \n",
       "10                      Tamil  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also specify the table if there are multiple tables.\n",
    "# Recall \"find\" function. You can add class, id, and other attributes as an argument.\n",
    "specific_table_html = str(soup.find('table', {'id': 'arpa-table'}))\n",
    "pd.read_html(specific_table_html)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b2164d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songt\\AppData\\Local\\Temp\\ipykernel_28320\\2354288201.py:7: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  table = pd.read_html(str(soup))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chart title</th>\n",
       "      <th>Chart type</th>\n",
       "      <th>Number of positions</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dance Club Songs</td>\n",
       "      <td>reports from DJs</td>\n",
       "      <td>50</td>\n",
       "      <td>Compiled exclusively from playlists submitted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hot Dance/Electronic Songs</td>\n",
       "      <td>Continuous airplay, single sales, digital down...</td>\n",
       "      <td>50</td>\n",
       "      <td>A chart which uses the same methodology as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dance/Mix Show Airplay</td>\n",
       "      <td>Continuous airplay (Spins from exclusive repor...</td>\n",
       "      <td>40</td>\n",
       "      <td>Originally called Hot Dance Airplay when it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dance/Electronic Digital Song Sales</td>\n",
       "      <td>digital sales</td>\n",
       "      <td>50</td>\n",
       "      <td>A chart that tracks the digital download sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dance/Electronic Streaming Songs</td>\n",
       "      <td>streaming</td>\n",
       "      <td>25</td>\n",
       "      <td>A chart that tracks the week's top Dance/Elect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Chart title  \\\n",
       "0                     Dance Club Songs   \n",
       "1           Hot Dance/Electronic Songs   \n",
       "2               Dance/Mix Show Airplay   \n",
       "3  Dance/Electronic Digital Song Sales   \n",
       "4     Dance/Electronic Streaming Songs   \n",
       "\n",
       "                                          Chart type  Number of positions  \\\n",
       "0                                   reports from DJs                   50   \n",
       "1  Continuous airplay, single sales, digital down...                   50   \n",
       "2  Continuous airplay (Spins from exclusive repor...                   40   \n",
       "3                                      digital sales                   50   \n",
       "4                                          streaming                   25   \n",
       "\n",
       "                                         Description  \n",
       "0  Compiled exclusively from playlists submitted ...  \n",
       "1  A chart which uses the same methodology as the...  \n",
       "2  Originally called Hot Dance Airplay when it wa...  \n",
       "3  A chart that tracks the digital download sales...  \n",
       "4  A chart that tracks the week's top Dance/Elect...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's spice things up!\n",
    "# The goal is to extract \"Dance/Electronic\" chart from the Wiki Billboard_charts page.\n",
    "response = requests.get('https://en.wikipedia.org/wiki/Billboard_charts')\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "# One easy solution is to read all tables\n",
    "table = pd.read_html(str(soup))\n",
    "# Then extract the table of interest\n",
    "table[4]\n",
    "# This is not a great strategy! Sometimes there may be too many tables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "30f8e727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"mw-heading mw-heading3\"><h3 id=\"Dance/Electronic\"><span id=\"Dance.2FElectronic\"></span>Dance/Electronic</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Billboard_charts&amp;action=edit&amp;section=9\" title=\"Edit section: Dance/Electronic\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An alternative is to pinpoint the path to the \"Dance/Electronic\" table\n",
    "# Note that this is a non trivial task\n",
    "# step1: Locate the word \"Dance/Electronic\"\n",
    "soup.find('h3',id='Dance/Electronic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b2fdb9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"mw-heading mw-heading3\"><h3 id=\"Dance/Electronic\"><span id=\"Dance.2FElectronic\"></span>Dance/Electronic</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Billboard_charts&amp;action=edit&amp;section=9\" title=\"Edit section: Dance/Electronic\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step2: Make your way up to the parent node with tag \"div\". This is because the \"table\" tag is a sibling of \"div\"\n",
    "soup.find('h3',id='Dance/Electronic').find_parent(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ce53a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songt\\AppData\\Local\\Temp\\ipykernel_28320\\1241850221.py:3: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dance_tab = pd.read_html(str(path_table))[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chart title</th>\n",
       "      <th>Chart type</th>\n",
       "      <th>Number of positions</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dance Club Songs</td>\n",
       "      <td>reports from DJs</td>\n",
       "      <td>50</td>\n",
       "      <td>Compiled exclusively from playlists submitted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hot Dance/Electronic Songs</td>\n",
       "      <td>Continuous airplay, single sales, digital down...</td>\n",
       "      <td>50</td>\n",
       "      <td>A chart which uses the same methodology as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dance/Mix Show Airplay</td>\n",
       "      <td>Continuous airplay (Spins from exclusive repor...</td>\n",
       "      <td>40</td>\n",
       "      <td>Originally called Hot Dance Airplay when it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dance/Electronic Digital Song Sales</td>\n",
       "      <td>digital sales</td>\n",
       "      <td>50</td>\n",
       "      <td>A chart that tracks the digital download sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dance/Electronic Streaming Songs</td>\n",
       "      <td>streaming</td>\n",
       "      <td>25</td>\n",
       "      <td>A chart that tracks the week's top Dance/Elect...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Chart title  \\\n",
       "0                     Dance Club Songs   \n",
       "1           Hot Dance/Electronic Songs   \n",
       "2               Dance/Mix Show Airplay   \n",
       "3  Dance/Electronic Digital Song Sales   \n",
       "4     Dance/Electronic Streaming Songs   \n",
       "\n",
       "                                          Chart type  Number of positions  \\\n",
       "0                                   reports from DJs                   50   \n",
       "1  Continuous airplay, single sales, digital down...                   50   \n",
       "2  Continuous airplay (Spins from exclusive repor...                   40   \n",
       "3                                      digital sales                   50   \n",
       "4                                          streaming                   25   \n",
       "\n",
       "                                         Description  \n",
       "0  Compiled exclusively from playlists submitted ...  \n",
       "1  A chart which uses the same methodology as the...  \n",
       "2  Originally called Hot Dance Airplay when it wa...  \n",
       "3  A chart that tracks the digital download sales...  \n",
       "4  A chart that tracks the week's top Dance/Elect...  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step3: As mentioned in Step2, \"table\" is the next sibling.\n",
    "path_table = soup.find('h3',id='Dance/Electronic').find_parent(\"div\").findNext(\"table\")\n",
    "dance_tab = pd.read_html(str(path_table))[0]\n",
    "dance_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666731a6",
   "metadata": {},
   "source": [
    "### Your Turn! -- Extract Table\n",
    "1. Use the following URL `\"https://en.wikipedia.org/wiki/Billboard_charts\"`\n",
    "2. Extract table for `R&B/Hip-Hop`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a97a46",
   "metadata": {},
   "source": [
    "## Saving the Outputs\n",
    "* It is important to know where your current working directory is\n",
    "* File will be saved to the current working directory unless it is specified\n",
    "* Use the `pandas` package to save the output in csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's amount Google Drive\n",
    "# We will save the output on Google Drive\n",
    "# Use the following code when working on Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b242e268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\songt\\\\Desktop\\\\WebScraping'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the working directory\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e988d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the \"dance_tab\" file\n",
    "# Name the file \"Billboard_Dance_Electronics.csv\"\n",
    "dance_tab.to_csv(\"Billboard_Dance_Electronics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10028b4f",
   "metadata": {},
   "source": [
    "### Selenium -- Automated Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-colab-selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bf89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code will not work\n",
    "response = requests.get(\"https://www.iborrowdesk.com/\")\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "table = pd.read_html(str(soup))\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google_colab_selenium as gs\n",
    "driver = gs.Chrome()\n",
    "driver.get(\"https://www.iborrowdesk.com/\")\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "table = pd.read_html(str(soup))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16390b60",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "* Next step is to create a loop to conduct multiple iterations for web crawling\n",
    "* Javascript embedded webpages will not work with HTTP request as they are dynamic\n",
    "* Use automated web browser such as `Selenium` to receive data\n",
    "* Use Proxy server to avoid bot detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "173ae74ecd759d33659dc89cc0ace91dba90ddaa088b7a848a7f37d845ddcc5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
